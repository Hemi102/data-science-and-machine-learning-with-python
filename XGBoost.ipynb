{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d444a32-f344-484f-956e-58fe8e483240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "4\n",
      "[np.str_('setosa'), np.str_('versicolor'), np.str_('virginica')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "numSamples, numFeatures = iris.data.shape\n",
    "print(numSamples)\n",
    "print(numFeatures)\n",
    "print(list(iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa8554fe-0dd2-4d6a-a517-08d4f9aaf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's divide our data into 20% reserved for testing our model, and the remaining 80% to train it with. By withholding our test data, we can make sure we're evaluating its results based on new flowers it hasn't seen before. Typically we refer to our features (in this case, the petal sizes) as X, and the labels (in this case, the species) as y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eea27724-1659-4928-8460-04d6fe528134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee50c75-090d-470e-96f0-5a93fea9d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll load up XGBoost, and convert our data into the DMatrix format it expects. One for the training data, and one for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52df1f4a-2d39-4065-9dac-f420028a03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "train = xgb.DMatrix(X_train, label= y_train)\n",
    "test = xgb.DMatrix(X_test, label= y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3e003c0-ec95-4b5a-9558-8485f3b7b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll define our hyperparameters. We're choosing softmax since this is a multiple classification problem, but the other parameters should ideally be tuned through experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe4ca167-0d0e-4ce4-a732-9e99bf87e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3\n",
    "}\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6680b7c-2495-48ae-acdd-87fd5327791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's go ahead and train our model using these parameters as a first guess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde77631-9b56-4856-b675-cdbdd59dbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(param, train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daa7f47f-a218-414e-a50a-9dc701ba6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll use the trained model to predict classifications for the data we set aside for testing. Each classification number we get back corresponds to a specific species of Iris.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f74cde7-57a2-4849-bebf-0f3fbe4ad20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbfe008a-bb35-4939-97ca-ff877a5b8f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 0. 2. 0. 2. 0. 1. 1. 1. 2. 1. 1. 1. 1. 0. 1. 1. 0. 0. 2. 1. 0. 0.\n",
      " 2. 0. 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c15618-30ae-4162-953a-1fc529f8a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's measure the accuracy on the test data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "017efdda-9362-4788-9efb-e221e26f4337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1344de19-76c1-40a1-a3a0-4d0ae779d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holy crow! It's perfect, and that's just with us guessing as to the best hyperparameters!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510986b4-b1b8-4107-9d45-5d6f36fde09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
